{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a324b5f7",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68f6d7d-6182-4a0b-81b0-00e105069ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from os import path\n",
    "from collections import namedtuple\n",
    "from math import sqrt\n",
    "from IPython.display import display\n",
    "from PIL import Image, ImageColor, ImageDraw\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "base_path = \"D:\\Vezdecode\\CV\\CV40\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c9ff42",
   "metadata": {},
   "source": [
    "# Determining the color of the car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d717d1-886f-45e0-a49e-817ddbb42956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_channels(input_dir:str, output_dir:str):\n",
    "    \"\"\"\n",
    "    Docstring:\n",
    "        input_dir — name of the directory containing the dataset\n",
    "        output_dir — name of the directory containing the RGB images\n",
    "    \"\"\"\n",
    "    \n",
    "    files = os.listdir(input_dir) # Reading files from the input directory\n",
    "    indexes = [ind.split(\"_\")[0] for ind in files] # Selection image indexes\n",
    "    \n",
    "    dict_with_channels = {} # Dictionary for storing channels and easy access to them\n",
    "    merged_img = None # Image template for combining channels\n",
    "    for index in tqdm(indexes):\n",
    "        # Reading and filling in the dictionary for one picture with the appropriate channels\n",
    "        for num, color in enumerate([\"b\", \"g\", \"r\"]): # The specific order of OpenCV colors\n",
    "            path_img = path.join(input_dir, index+f\"_{color}.jpg\")\n",
    "            \n",
    "            merged_img = cv.imread(path_img)\n",
    "            \n",
    "            dict_with_channels[num] = merged_img[:, :, num]\n",
    "        \n",
    "        for num_channel in range(0, 3):\n",
    "            merged_img[:, :, num_channel] = dict_with_channels[num_channel]\n",
    "            \n",
    "        cv.imwrite(path.join(output_dir, index+\".jpg\"), merged_img) # Saving the final image\n",
    "         \n",
    "def centroid_histogram(clt):\n",
    "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(clt.labels_, bins = numLabels)\n",
    "\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "\n",
    "    return hist\n",
    "\n",
    "def dominant_colors(perc_colors, centroids):\n",
    "    if sum(centroids[0]) < 20:\n",
    "        return centroids[1]\n",
    "    else:\n",
    "        return centroids[0]\n",
    "\n",
    "def calc_metric(image, x=None, y=None, w=None, h=None):    \n",
    "    if None not in [x, y, w, h]:\n",
    "        image = image[y:y+h, x:x+w, :]\n",
    "    \n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "\n",
    "    clt = KMeans(n_clusters=3)\n",
    "\n",
    "    clt.fit(image)\n",
    "        \n",
    "    perc_colors = centroid_histogram(clt)\n",
    "    max_color = dominant_colors(perc_colors, clt.cluster_centers_)\n",
    "    \n",
    "    return tuple((np.array(max_color)*255).round().astype(\"int\"))\n",
    "\n",
    "def find_car(image, model):\n",
    "    results = model(image).crop(save=False)\n",
    "    \n",
    "    square = 0\n",
    "    ind_car = 0\n",
    "    cars = []\n",
    "    \n",
    "    for c in results:\n",
    "        if \"car\" in c[\"label\"]:\n",
    "            cars.append(c)\n",
    "    \n",
    "    for num, car in enumerate(cars):\n",
    "        if len(cars) == 1:\n",
    "            break\n",
    "        \n",
    "        x = int(car[\"box\"][0].cpu().item())\n",
    "        y = int(car[\"box\"][1].cpu().item())\n",
    "        w = int(car[\"box\"][2].cpu().item())\n",
    "        h = int(car[\"box\"][3].cpu().item())\n",
    "        \n",
    "        s = (w-x) * (h-y)\n",
    "\n",
    "        if s > square:\n",
    "            square = s\n",
    "            ind_car = num\n",
    "            \n",
    "    if len(cars) == 0:\n",
    "        return np.array([s.cpu().item() for s in results[0][\"box\"]]).round().astype(\"int\")\n",
    "    \n",
    "    return np.array([s.cpu().item() for s in cars[ind_car][\"box\"]]).round().astype(\"int\")\n",
    "\n",
    "def find_color(input_dir, output_file=\"output_color.csv\"):\n",
    "    model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n",
    "    \n",
    "    files = [path.join(input_dir, img) for img in os.listdir(input_dir)]\n",
    "    \n",
    "    result_df = pd.DataFrame(columns=[\"image\", \"color\"])\n",
    "    name_images = [] # A list for saving image names\n",
    "    pred_colors = [] # A list for saving the prediction of the presence of a car in the image\n",
    "    \n",
    "    for img in tqdm(files):\n",
    "        name_images.append(img.split(\"\\\\\")[-1])\n",
    "        \n",
    "        image = cv.imread(img)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        x, y, w, h = find_car(image, model)\n",
    "        \n",
    "        color = calc_metric(image / 255., x, y, w, h)\n",
    "        min_dist = 10000\n",
    "        near_color = None\n",
    "        \n",
    "        for clr in dict_colors.keys():\n",
    "            dist = ColorDistance(dict_colors[clr], color)\n",
    "            \n",
    "            if min_dist > dist:\n",
    "                min_dist = dist\n",
    "                near_color = clr\n",
    "                \n",
    "        pred_colors.append(near_color)\n",
    "    \n",
    "    result_df[\"image\"] = name_images\n",
    "    result_df[\"color\"] = pred_colors\n",
    "\n",
    "    result_df.to_csv(output_file, index=False, header=False)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def ColorDistance(rgb1, rgb2):\n",
    "    rgb1 = np.array(rgb1)\n",
    "    rgb2 = np.array(rgb2)\n",
    "    \n",
    "    d = ((rgb2[0] - rgb1[0]) ** 2 + (rgb2[1] - rgb1[1]) ** 2 + (rgb2[2] - rgb1[2]) ** 2) ** 0.5\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a34e81-e8aa-476a-988d-7e90c6aac247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54517589a64f440cbea43359d19f8f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "channels_data = path.join(base_path, \"resources\\data\")\n",
    "merged_data_path = path.join(base_path, \"resources\\merged_data\")\n",
    "\n",
    "dir_with_data = merged_data_path\n",
    "\n",
    "files = [path.join(base_path, dir_with_data, img) for img in os.listdir(dir_with_data)]\n",
    "\n",
    "merge_channels(channels_data, merged_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa069c9-0b7d-43a2-bf09-c48f74d4724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path.join(base_path, \"resources\\colors.csv\"), header=None, names=[\"images\", \"color\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d4e98a7-b65f-473f-97ab-c30582a998e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'white_silver': (192, 192, 192),\n",
       " 'black': (0, 0, 0),\n",
       " 'blue_cyan': (0, 255, 255),\n",
       " 'yellow': (255, 255, 0),\n",
       " 'red': (255, 0, 0),\n",
       " 'green': (0, 128, 0)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_colors = {}\n",
    "\n",
    "for color in [\"silver\", \"black\", \"cyan\", \"yellow\", \"red\", \"green\"]:\n",
    "    if \"cyan\" in color:\n",
    "        _key = \"blue_cyan\"\n",
    "        dict_colors[_key] = ImageColor.getcolor(color, \"RGB\")\n",
    "    elif \"silver\" in color:\n",
    "        _key = \"white_silver\"\n",
    "        dict_colors[_key] = ImageColor.getcolor(color, \"RGB\")\n",
    "    else:\n",
    "        dict_colors[color] = ImageColor.getcolor(color, \"RGB\")\n",
    "\n",
    "dict_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46dbf1dd-72f5-4f5a-a459-20a892434d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\USER/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-6-18 Python-3.8.11 torch-1.10.1+cu113 CUDA:0 (NVIDIA GeForce GTX 1050, 3072MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25572f21f4024a7bbd500a4b12d0e033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: NMS time limit 0.330s exceeded\n"
     ]
    }
   ],
   "source": [
    "input_dir = path.join(base_path, \"resources\\merged_data\")\n",
    "\n",
    "output_df = find_color(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5727998-3cd4-4ced-bb8d-4a6267b62644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.jpg</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002.jpg</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003.jpg</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004.jpg</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00005.jpg</td>\n",
       "      <td>white_silver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image         color\n",
       "0  00001.jpg        yellow\n",
       "1  00002.jpg        yellow\n",
       "2  00003.jpg         green\n",
       "3  00004.jpg         black\n",
       "4  00005.jpg  white_silver"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_target = pd.read_csv(\n",
    "    path.join(base_path, \"resources\\\\colors.csv\"), \n",
    "    header=None, names=[\"image\", \"color\"]\n",
    ")\n",
    "\n",
    "valid_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7366f1b-3f28-4612-9dde-61a471d0dcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.458333333333332"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = sum(output_df[\"color\"] == valid_target[\"color\"])\n",
    "N = len(valid_target)\n",
    "score = max(0, K - 0.2 * N) * 40 / (N - 0.2 * N)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
